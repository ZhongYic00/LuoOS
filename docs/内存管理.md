# 内存管理
内存管理分为两个方面，其一是虚拟内存空间的管理，其二是物理内存资源的管理。前者即内核、用户进程内存空间的设计，及页表的创建增删；后者又分为以物理页帧为单位的管理和用于动态内存分配的内核堆管理。以下将从两方面分别介绍其功能实现。  
### 虚拟内存空间  
#### 内存布局  
内核视角下的内存环境通常有两种选择：shared address space与dedicated kernel space（引述自The Linux Kernel  documentation）。权衡安全性、性能、实现复杂性后，我们采用了专有内核空间的设计，即所有内核线程共享一个内核地址空间、内核地址空间与用户地址空间可重叠。在陷入的入口处，我们将`satp`切换为内核页表，在出口切换回用户页表。  
该种设计需要trampoline，现阶段我们是将整个内核的代码段与静态数据段映射至进程地址空间，将每个进程的trapframe映射至其地址空间，后续可通过链接脚本和`__attribute((section))__`将所用到的部分剥离出来。  
目前内核内存空间采用线性映射，布局如下：  
```
------------------- 0x0
device mmio
------------------- 0x40000000
opensbi
------------------- 0x80200000
kernel text
............ 
kernel data
............
kernel trap stacks
............
kernel bss
.......
uimg (init.elf二进制拷贝)
------------------- kernel_end / _frames_start
frames
------------------- physical frames end
```
#### 页表管理  
页表采用`PageTable` 类封装了RISC-V标准定义的Sv39页表模式下的页表操作，包括创建映射、删除映射、虚实地址转换等。为提高效率（如内核空间线性映射了 `0x0-0x40000000` 的MMIO设备区间），我们支持了根据对齐情况自动使用不同的页大小，具体实现如下。该部分主要参考标准自行实现。  
首先是相关类的设计，主要为`PageTable`类和`PageTableEntry`类，如下所示：  
``` c++
union PageTableEntry{	//用一个Union建模，以同时支持按细粒度读写和整个表项读写
    struct Fields{
      ...	// 这部分按照Sv39标准从低到高分别定义了v/r/w/x/u/g/a/d位域
        // 分别表示有效、读、写、执行、用户态、不分进程全局有效、访问位、脏页
        xlen_t _rsw:2;	//预留
      xlen_t ppn0:9,ppn1:9,ppn2:26;	//三级页表，支持big page所以表项的ppn也分三部分
    }fields;
    struct Raw{
      xlen_t perm:8;	//对应上面定义的8个位域
      xlen_t _rsw:2;
      xlen_t ppn:44;	//物理页号
    }raw;
    enum fieldMasks{};	//用于支持类似于 mask::r|mask::w|mask::x这样的写法
    // 将当前页表项设为中间节点，根据定义非叶节点的rwx位必须为0，v为1
    inline void setPTNode(){ fields.r=fields.w=fields.x=0; }
    // 同上，判断是否为叶节点
    inline bool isLeaf(){ return fields.r|fields.w|fields.x; }
    // 取当前页表项所代表的子页表节点
    inline pgtbl_t child(){ return reinterpret_cast<pgtbl_t>( pn2addr(ppn()) ); }
};
```
其中Sv39模式有如下特性：根据三级页表的设计，每个虚拟空间最多可达 $2^{39}$ 字节，而根据页表项的设计，总共可使用的物理内存则为 $2^{44}$ 字节。  
而`PageTable`类则主要具有如下方法：  
``` c++
class PageTable{
  private:
    pgtbl_t root;	//页表根节点地址，pgtbl_t就是一个PageTableEntry的数组类型
  public:
    // 初始化页表，如果传入的root为0会自动从PageMgr获取一个页帧作为根节点
    inline PageTable(pgtbl_t root)
    // 创建从vpn到ppn长度为pages的映射，该区域权限为perm
    inline void createMapping(PageNum vpn,PageNum ppn,xlen_t pages,perm_t perm)
    PageNum trans(PageNum vpn);	//按规则沿着页表一级级走，得到vpn对应的物理页号
    inline xlen_t transaddr(xlen_t addr){
      // 物理地址则是翻译的物理页地址+原始的12位页内offset
      return pn2addr(trans(addr2pn(addr)))+addr2offset(addr);
    }
    static xlen_t toSATP(PageTable &table);	//根据当前页表根地址算satp寄存器值
    inline klib::ByteArray copyin(xlen_t addr,size_t len)	//从用户地址空间拷进内核
};
```
其中`createMapping`的实现大致如下：  
``` C++
void PageTable::createMapping(pgtbl_t table,...){
    xlen_t bigPageSize=1l<<(9*level);	// 当前一级页表表项所管理的页数
    xlen_t unaligned=vpn&(bigPageSize-1);	// 非对齐部分有多少页
    // align vpn to boundary 先处理非对齐的页
    if(unaligned){
        auto partial=klib::min(bigPageSize-unaligned,pages);
        PageTableEntry &entry=table[(vpn/bigPageSize)&vpnMask];
      	// 先得把当前这个entry变成中间节点
        if(entry.isValid() && !entry.isLeaf()){
          // if the range is previously managed, and is not bigPage
            subTable=entry.child();
        } else {	// 可能是之前没创建子节点，也可能之前按bigPage映射了
            subTable=createPTNode();
            if(entry.isValid() && entry.isLeaf()){
                ... 这部分就是把之前创建的整页映射下推，拆散
                createMapping(subTable,vpn-unaligned,prevppn,unaligned,prevPerm,level-1);
            }
            entry.setValid();entry.raw.ppn=addr2pn(reinterpret_cast<xlen_t>(subTable));
        }
        createMapping(subTable,vpn,ppn,partial,perm,level-1); // actual create mapping
        vpn+=partial,ppn+=partial,pages-=partial;
    }
    // map aligned whole pages 按照大页（当前级别的页大小）映射
    for(int i=(vpn/bigPageSize)&vpnMask;pages>=bigPageSize;i++){
        // create big page entry
        PageTableEntry &entry=table[i];
        ...
        vpn+=bigPageSize;ppn+=bigPageSize;pages-=bigPageSize;
    }
    // map rest pages
    if(pages){
      	// 还有一些不足一个bigPage的区域，对应的该级表项为vpn/bigPageSize
        PageTableEntry &entry=table[(vpn/bigPageSize)&vpnMask];
      	// 该部分同上述unaligned情况
    }
}
```
### 内存资源分配  
内存资源分配分为页帧与堆内存管理，是因为考虑到效率及进程等对对齐页的需求，不可能以全部内存空间作为内核堆管理，而是应当使用部分页作为内核堆，堆内存不够了再去申请。综合考虑效率及实现难度，我们使用了伙伴算法实现页帧管理，而在内核堆部分引入了第三方的`tlsf`算法。该部分参考了浙江大学OSLab，以及上学期OS案例分析中分析的OpenHarmony操作系统。  
#### 页帧分配  
页帧分配由 `PageMgr` 实现，采用了伙伴算法，算法的实现使用数组下标表示节点关系。该实现参考了浙大OSLab，部分关键细节如下：  
``` C++
// 数组里的每个单元是一个节点，节点间的关系通过下标的数学关系表示
// 左节点是当前*2-1，右节点是当前*2，而亲本节点是当前/2-1
inline constexpr xlen_t lsub(xlen_t x){return ((x+1)<<1)-1;}
inline constexpr xlen_t rsub(xlen_t x){return ((x+1)<<1);}
inline constexpr xlen_t prnt(xlen_t x){return ((x+1)>>1)-1;}
// 这个函数是已知所需区间的起址和长度（二的幂表示），求所对应的节点下标
inline xlen_t pos2node(xlen_t pos,int order)
xlen_t alloc(size_t pages);		// 申请pages个页帧，返回起址页号
xlen_t free(xlen_t addr,int order);	// 释放addr处2^order个页
```
值得注意的是，我们的页帧管理器支持任意（非二的幂数）页数的管理，在初始化页帧管理器时为了简便与代码复用，采用如下方法：  
``` c++
buddyNodes=new uint8_t[buddyTreeSize];	//这里可以看出PageMgr是依赖内核堆的
...
{xlen_t base=start;
 for(int i=rootOrder;i>=0;i--){
   if((pages>>i)&1){
     // 就是从高到低，依次取总页数中的整2^i页添加到已添加区域的末尾
     free(base,i);	// 初始化实际上和释放做的事情相同
     base+=(1l<<i);
   }
 }}
```
#### 内核堆  
内核堆内存分配由 `HeapMgr` 实现，又分为不可扩充的内核堆与可扩充的内核堆 `HeapMgrGrowable` ，其内部均采用TLSF算法的第三方开源实现。不可扩充内核堆主要用于 `PageMgr` 初始化前的内核内存管理，其使用静态分配的 `pool` 作为唯一的内存池，页帧分配器从中申请得到伙伴系统所使用的内存区段。可扩充内核堆主要是在当前内存池中分配失败时，向页帧分配器请求一定数量的页作为新内存池并记录于链表中。  